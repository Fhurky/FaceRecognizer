{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dfde96-17f2-4ad9-8e5a-4ef1fb03417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9484e6fd-da1b-4be6-9a42-f00049b97b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow dependencies\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683b01c9-6ad0-45b4-a01c-8cd2587fc042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by seetting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # All GPUs\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab3160f-2b11-484d-bbe0-16620156b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths and Make directories\n",
    "POS_PATH = os.path.join('data','positive')\n",
    "NEG_PATH = os.path.join('data','negative')\n",
    "ANC_PATH = os.path.join('data','anchor')\n",
    "#os.makedirs(POS_PATH)\n",
    "#os.makedirs(NEG_PATH)\n",
    "#os.makedirs(ANC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6b6b3b3-f708-46d7-aaf7-29cd231423d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar -xf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f84c9-ebe1-4e10-850e-b1225105fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images to negative repo\n",
    "for directory in os.listdir('lfw'):\n",
    "    for file in os.listdir(os.path.join('lfw',directory)):\n",
    "        EX_PATH = os.path.join('lfw', directory, file)\n",
    "        NEW_PATH = os.path.join(NEG_PATH, file)\n",
    "        os.replace(EX_PATH, NEW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a98a90ea-18bd-487c-8c34-062c847d73f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5122b74-f99d-49aa-8430-537a360978ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # to 250x 250\n",
    "    frame = frame[120:120+250,200:200+250,:]\n",
    "\n",
    "    # Collect anchors\n",
    "    if cv2.waitKey(1) & 0XFF == ord('a'):\n",
    "        # Create unique file path\n",
    "        imgname = os.path.join(ANC_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        \n",
    "    # Collect positives\n",
    "    if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "        # Create unique file path\n",
    "        imgname = os.path.join(POS_PATH, '{}.jpg'.format(uuid.uuid1()))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        \n",
    "    #show image on to the screen\n",
    "    cv2.imshow('Camera', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61b3142-c9c1-4654-a0d2-59738c4d08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(400)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(400)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd1f843f-fd98-4ac1-a9f3-63e5aeab6494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'data\\\\anchor\\\\1ec1e54b-6d48-11ef-9a54-089798a32039.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_test = anchor.as_numpy_iterator()\n",
    "dir_test.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f564783a-0f70-4f2c-b5a6-de6abe574968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprogress(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (100, 100))\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "899475a2-06ee-41ba-8d1d-e47a311a50c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprogress('data\\\\anchor\\\\1101d7af-6d48-11ef-93b9-089798a32039.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2411c-62b9-4c19-a953-faef16f4ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c5256-c054-4e3e-8356-779f385a0fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.map(preprogress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8259539-578e-4c11-b486-ede5466c060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15c80ec8-805b-4b14-baa7-b3e590ca0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a03e4a73-5afe-498d-946a-f5ea732d7e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6de85e50-83dc-4034-8c19-b6f8f04a13ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprogress_twin(input_img, validation_img, label):\n",
    "    return(preprogress(input_img), preprogress(validation_img), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b75cfb5f-edf9-4b99-9406-b19b705dfeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[0.3502451 , 0.34632352, 0.2757353 ],\n",
       "         [0.3394608 , 0.33161765, 0.2747549 ],\n",
       "         [0.32058823, 0.31862745, 0.27058825],\n",
       "         ...,\n",
       "         [0.22328432, 0.2625    , 0.26740196],\n",
       "         [0.24558823, 0.28480393, 0.29264706],\n",
       "         [0.26544118, 0.3007353 , 0.32034314]],\n",
       " \n",
       "        [[0.35882354, 0.34411764, 0.28039217],\n",
       "         [0.3389706 , 0.32647058, 0.26985294],\n",
       "         [0.3156863 , 0.30759802, 0.25465685],\n",
       "         ...,\n",
       "         [0.22254902, 0.2615196 , 0.26789215],\n",
       "         [0.24338235, 0.28161764, 0.29240197],\n",
       "         [0.25906864, 0.29730392, 0.30808824]],\n",
       " \n",
       "        [[0.35      , 0.32647058, 0.26568627],\n",
       "         [0.3362745 , 0.3245098 , 0.25980392],\n",
       "         [0.3247549 , 0.32083333, 0.24436274],\n",
       "         ...,\n",
       "         [0.22696078, 0.2637255 , 0.2884804 ],\n",
       "         [0.24068627, 0.28186274, 0.3       ],\n",
       "         [0.26078433, 0.3019608 , 0.31862745]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.85539216, 0.86715686, 0.79901963],\n",
       "         [0.79583335, 0.8115196 , 0.7536765 ],\n",
       "         [0.7676471 , 0.78039217, 0.7343137 ],\n",
       "         ...,\n",
       "         [0.3882353 , 0.40784314, 0.38259804],\n",
       "         [0.35441175, 0.37083334, 0.3409314 ],\n",
       "         [0.31813726, 0.33161765, 0.30906862]],\n",
       " \n",
       "        [[0.8865196 , 0.9012255 , 0.83455884],\n",
       "         [0.8953431 , 0.9110294 , 0.85245097],\n",
       "         [0.889951  , 0.90343136, 0.8401961 ],\n",
       "         ...,\n",
       "         [0.39142156, 0.42769608, 0.39632353],\n",
       "         [0.35735294, 0.39436275, 0.35784313],\n",
       "         [0.32647058, 0.3627451 , 0.33137256]],\n",
       " \n",
       "        [[0.86470586, 0.88039213, 0.8215686 ],\n",
       "         [0.86764705, 0.8833333 , 0.81666666],\n",
       "         [0.8654412 , 0.8784314 , 0.80514705],\n",
       "         ...,\n",
       "         [0.37696078, 0.4122549 , 0.39264706],\n",
       "         [0.3740196 , 0.41004902, 0.3882353 ],\n",
       "         [0.3735294 , 0.40882352, 0.39117646]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[0.34705883, 0.35490197, 0.26862746],\n",
       "         [0.33431372, 0.34117648, 0.2622549 ],\n",
       "         [0.3137255 , 0.31691176, 0.2615196 ],\n",
       "         ...,\n",
       "         [0.2531863 , 0.24289216, 0.21740197],\n",
       "         [0.27450982, 0.28137255, 0.26078433],\n",
       "         [0.2860294 , 0.3125    , 0.29583332]],\n",
       " \n",
       "        [[0.3382353 , 0.35196078, 0.27058825],\n",
       "         [0.3394608 , 0.3526961 , 0.27107844],\n",
       "         [0.32254902, 0.33431372, 0.25784314],\n",
       "         ...,\n",
       "         [0.24828431, 0.24754901, 0.22867647],\n",
       "         [0.2617647 , 0.27769607, 0.2637255 ],\n",
       "         [0.28529412, 0.32058823, 0.30882353]],\n",
       " \n",
       "        [[0.34509805, 0.35882354, 0.28480393],\n",
       "         [0.3394608 , 0.3526961 , 0.26960784],\n",
       "         [0.32181373, 0.3375    , 0.24289216],\n",
       "         ...,\n",
       "         [0.23627451, 0.24411765, 0.2382353 ],\n",
       "         [0.25980392, 0.28161764, 0.2784314 ],\n",
       "         [0.29411766, 0.32058823, 0.31176472]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.82058823, 0.86470586, 0.79509807],\n",
       "         [0.7943627 , 0.8370098 , 0.76740193],\n",
       "         [0.7529412 , 0.7889706 , 0.720098  ],\n",
       "         ...,\n",
       "         [0.43504903, 0.43946078, 0.42941177],\n",
       "         [0.3875    , 0.38602942, 0.37156862],\n",
       "         [0.35759804, 0.35563725, 0.3389706 ]],\n",
       " \n",
       "        [[0.8186275 , 0.8715686 , 0.78431374],\n",
       "         [0.8375    , 0.8845588 , 0.8002451 ],\n",
       "         [0.84632355, 0.89117646, 0.8120098 ],\n",
       "         ...,\n",
       "         [0.43676472, 0.43382353, 0.4259804 ],\n",
       "         [0.41666666, 0.41887254, 0.40220588],\n",
       "         [0.3882353 , 0.39215687, 0.37254903]],\n",
       " \n",
       "        [[0.810049  , 0.86495095, 0.7747549 ],\n",
       "         [0.82254905, 0.8754902 , 0.7862745 ],\n",
       "         [0.8382353 , 0.88529414, 0.79901963],\n",
       "         ...,\n",
       "         [0.39632353, 0.38946077, 0.39044118],\n",
       "         [0.41838235, 0.41740197, 0.40955883],\n",
       "         [0.4127451 , 0.42058823, 0.40098038]]], dtype=float32)>,\n",
       " 1.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprogress_twin(*example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ffdb37b-b5ca-4b7b-bf9b-2146ca549957",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preprogress_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f96b63bf-8993-417e-ae30-6697f838c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training partition\n",
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0239608-9f45-496d-b8ad-55bcf74adb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*3))\n",
    "test_Data = test_data.batch(16)\n",
    "test_Data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14765374-3a63-4034-a462-23a1ebf5ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(100,100,3), name='input_image')\n",
    "c1 = Conv2D(64, (10,10), activation='relu')(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4a8ff44-44a7-49c4-b185-b6c2ae281616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 91, 91, 64) dtype=float32 (created by layer 'conv2d')>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20eb0dd0-b880-43fa-9da4-5b58b4e2634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inp = Input(shape=(100,100,3), name='input_image')\n",
    "    \n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "    \n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    \n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd615ae7-2fde-4b21-bc68-cb61b6b8686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41128933-03a4-4a45-81a6-75c03f486858",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1721826d-1e4f-4f93-8398-bcb619452e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9e8a332-b589-4cd5-9b22-960d4001d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = L1Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ac618a1-bbbf-4c58-80cd-d80b366e0010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.L1Dist at 0x19f06fef8e0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58cdb4d6-a0cd-4b96-aaad-e16c2306b6f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anchor_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m L1(\u001b[43manchor_embedding\u001b[49m, validation_embedding)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'anchor_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "L1(anchor_embedding, validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae56f3-3302-4f37-a006-2aa1ad7149c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
